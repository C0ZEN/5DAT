# 3 - Introduction to Hadoop

### Problématique

Lenteur de lecture des données (trop volumineux)
Lorsque les disques sont volumineux

### Solution

Stocker les données sur plusieurs
Accès en lecture beaucoup plus rapide
Hadoop fournit la solution

### Hadoop

Permet donc de lire les disques
De les associers
Il permet également de faire des requêtes

Basé sur un système de nodes

### Origine

Yahoo avec Hadoop
1000 coeurs (noeuds)
Apache Top-Level (projet important)

Utilisé par :

- Facebook
- Last.fm
- DAF
- Google
- Amazon

### Ecosystème

Framework open-source
Pour le traitement de données massives
Fiable
Scalable
Couche abstraction

Pig

- Language pour requêter les dataset (abstraction)
- Select classique (mais pourtant requêtes complexes)

Hive

- Entrepot de données distribué sur plusieurs machines
- HQL (similaire au SQL, pour requête le datawerehouse)

HBase

- Répartion en column-family
- Sur un système distribué

Mahout

- Librairie de machine learning

Flume

- Live streaming

Oozie

- Programmation de tâches (workflow)
- Pour Hadoop (scipts)

### Example

Compter le nombre d'ocurrence de chaque mot dans un fichier texte

- Créer un compteur init à 0
- Découper le document pour chaque mot
- Pour chacun des mots, on incrémente le compteur
- Puis affiche la valeur du compteur

Faire ça sur une seule machine, c'est lent  
Sur des machines distribuées, le charge est répartie  
C'est beaucoup plus rapide parceque les traitements sont en parallèles

### Map reduce

Données à traiter en entrée  
Eclate un requêtage en X sous éléments  
Puis grouper par famille  
Fusionne les familles de chaque sous éléments  
Fusionne les familles pour avoir le résultat de la request

**Map :**

- Trie les données en catégories (plusieurs bloc de data)

**Shuffle :**

- Prend les catégories de chaque map
- Concatène en un résultat final

**Reduce :**

- Addition les catégories
- 1 seul résultat en sortie

### HDFS (Hadoop Distributed File System)

Les données sont stockées dans des "units" en tant que "blocks"  
De 64mb  
Une vidéo est donc généralement stockée sur plusieurs fichiers  
Et sur plusieurs nodes

Les nodes sont répliqués (haute dispo)

**Example :**

Un fichier  
Découpagé en 3 blocks  
Chaque block sera répartie sur 3 nodes

```
hadoop fs ...
```

